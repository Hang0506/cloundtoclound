import streamlit as st

def collect_user_input(use_demo=False):
    # N·∫øu s·ª≠ d·ª•ng demo, load demo data
    demo_data = None
    if use_demo:
        demo_data = create_demo_data()
    
    # ƒê·∫∑t selectbox n√†y ngo√†i form ƒë·ªÉ Streamlit rerun khi ch·ªçn
    migration_type = st.selectbox(
        "üîÑ Ki·ªÉu migration",
        ["On-Premise ‚ûú Cloud", "Cloud ‚ûú Cloud"],
        index=1 if use_demo else 0,  # Ch·ªçn Cloud ‚ûú Cloud n·∫øu demo
        help="Ch·ªçn ki·ªÉu migration: t·ª´ h·ªá th·ªëng t·∫°i ch·ªó l√™n Cloud, ho·∫∑c t·ª´ Cloud n√†y sang Cloud kh√°c. S·ª≠ d·ª•ng ph√≠m Tab ƒë·ªÉ di chuy·ªÉn gi·ªØa c√°c tr∆∞·ªùng.",
        key="migration_type_selectbox"
    )

    # N·∫øu l√† Cloud ‚ûú Cloud, ch·ªçn cloud_source ngo√†i form ƒë·ªÉ d√πng trong form
    cloud_source = None
    if migration_type == "Cloud ‚ûú Cloud":
        cloud_options = ["FCI Cloud", "AWS RDS", "Azure SQL", "Google Cloud SQL"]
        default_index = 1 if use_demo else 0  # AWS RDS cho demo
        cloud_source = st.selectbox(
            "üå©Ô∏è Cloud ngu·ªìn",
            cloud_options,
            index=default_index,
            help="Ch·ªçn Cloud ngu·ªìn n·∫øu migration gi·ªØa c√°c Cloud. V√≠ d·ª•: AWS RDS.",
            key="cloud_source_cloud2cloud"
        )

    with st.form("input_form"):
        if migration_type == "On-Premise ‚ûú Cloud":
            row1_col1, row1_col2, row1_col3 = st.columns([1, 1, 1])
            with row1_col1:
                db_type = st.selectbox(
                    "üîç Lo·∫°i C∆° s·ªü d·ªØ li·ªáu",
                    ["PostgreSQL", "SQL Server", "MySQL", "MongoDB"],
                    help="Ch·ªçn lo·∫°i CSDL b·∫°n mu·ªën migration. V√≠ d·ª•: PostgreSQL, SQL Server, MySQL, MongoDB.",
                    key=f"db_type_{migration_type}"
                )
            with row1_col2:
                version = st.text_input(
                    "üßæ Phi√™n b·∫£n",
                    "14",
                    help="Nh·∫≠p phi√™n b·∫£n CSDL hi·ªán t·∫°i. V√≠ d·ª•: 14 cho PostgreSQL.",
                    key=f"version_{migration_type}"
                )
            with row1_col3:
                data_size = st.text_input(
                    "üíæ Dung l∆∞·ª£ng d·ªØ li·ªáu",
                    "1.2TB",
                    help="T·ªïng dung l∆∞·ª£ng d·ªØ li·ªáu c·∫ßn migration. V√≠ d·ª•: 1.2TB.",
                    key=f"data_size_{migration_type}"
                )

            row2_col1, row2_col2, row2_col3 = st.columns([1, 1, 1])
            with row2_col1:
                bandwidth = st.text_input(
                    "üåê BƒÉng th√¥ng m·∫°ng",
                    "5Gbps",
                    help="BƒÉng th√¥ng m·∫°ng hi·ªán c√≥ cho migration. V√≠ d·ª•: 5Gbps.",
                    key=f"bandwidth_{migration_type}"
                )
            with row2_col2:
                downtime = st.text_input(
                    "‚è± Downtime t·ªëi ƒëa",
                    "10 ph√∫t",
                    help="Th·ªùi gian downtime t·ªëi ƒëa cho ph√©p. V√≠ d·ª•: 10 ph√∫t.",
                    key=f"downtime_{migration_type}"
                )
            with row2_col3:
                cloud_target = st.selectbox(
                    "‚òÅÔ∏è Cloud ƒë√≠ch",
                    ["FCI Cloud", "AWS RDS", "Azure SQL", "Google Cloud SQL"],
                    help="Ch·ªçn Cloud ƒë√≠ch sau migration. V√≠ d·ª•: Google Cloud SQL.",
                    key=f"cloud_target_target_{migration_type}"
                )

            row3_col1, row3_col2, row3_col3 = st.columns([1, 1, 1])
            with row3_col1:
                security_level = st.selectbox(
                    "üîê M·ª©c ƒë·ªô b·∫£o m·∫≠t",
                    ["Chu·∫©n doanh nghi·ªáp", "Tu√¢n th·ªß PCI DSS", "Tu√¢n th·ªß ISO 27001", "Cao nh·∫•t c√≥ th·ªÉ"],
                    help="Ch·ªçn m·ª©c ƒë·ªô b·∫£o m·∫≠t y√™u c·∫ßu. V√≠ d·ª•: Tu√¢n th·ªß PCI DSS.",
                    key=f"security_{migration_type}"
                )
            with row3_col2:
                system_scale = st.selectbox(
                    "üè¢ Quy m√¥ h·ªá th·ªëng",
                    [ "T·∫≠p ƒëo√†n l·ªõn", "Doanh nghi·ªáp nh·ªè", "Doanh nghi·ªáp v·ª´a", "D·ªØ li·ªáu tr·ªçng y·∫øu"],
                    help="Ch·ªçn quy m√¥ h·ªá th·ªëng c·ªßa b·∫°n. V√≠ d·ª•: Doanh nghi·ªáp nh·ªè.",
                    key=f"system_scale_{migration_type}"
                )
            # row3_col3 ƒë·ªÉ tr·ªëng cho c√¢n ƒë·ªëi
            replication_type = None
            cloud_tool = None
            cloud_source_region = None
            cloud_target_region = None
            is_live_system = None
            ha_required = None
            vpc_configured = None
            rollback_strategy = None
        else:  # Cloud ‚ûú Cloud
            cloud_db_options = {
                "FCI Cloud": [
                    "IBM Db2",
                    "PostgreSQL (Managed by IBM)",
                    "Cloud SQL",
                    "Oracle on FCI"
                ],
                "AWS RDS": [
                    "Amazon Aurora",
                    "PostgreSQL",
                    "MySQL",
                    "SQL Server",
                    "MariaDB",
                    "Oracle"
                ],
                "Azure SQL": [
                    "Azure SQL Database",
                    "PostgreSQL (Azure)",
                    "MySQL (Azure)",
                    "SQL Server (Azure)"
                ],
                "Google Cloud SQL": [
                    "Cloud SQL for PostgreSQL",
                    "Cloud SQL for MySQL",
                    "Cloud SQL for SQL Server"
                ]
            }
            db_cloud_options = cloud_db_options.get(cloud_source, ["PostgreSQL", "MySQL", "SQL Server", "MongoDB"])

            row1_col1, row1_col2, row1_col3 = st.columns([1, 1, 1])
            with row1_col1:
                db_type = st.selectbox(
                    f"üîç Lo·∫°i Database c·ªßa {cloud_source}",
                    db_cloud_options,
                    index=db_cloud_options.index(get_demo_value(demo_data, "db_type", "PostgreSQL")) if use_demo and get_demo_value(demo_data, "db_type", "PostgreSQL") in db_cloud_options else 0,
                    help=f"Ch·ªçn lo·∫°i database ph√π h·ª£p v·ªõi {cloud_source}.",
                    key=f"db_type_{cloud_source}_{migration_type}"
                )
            with row1_col2:
                cloud_target_options = ["AWS", "FCI Cloud", "Azure", "Google Cloud"]
                cloud_target = st.selectbox(
                    "‚òÅÔ∏è Cloud ƒë√≠ch",
                    cloud_target_options,
                    index=cloud_target_options.index(get_demo_value(demo_data, "cloud_target", "Azure")) if use_demo and get_demo_value(demo_data, "cloud_target", "Azure") in cloud_target_options else 0,
                    help="Ch·ªçn Cloud ƒë√≠ch sau migration. V√≠ d·ª•: Google Cloud SQL.",
                    key=f"cloud_target_source_{migration_type}"
                )
            with row1_col3:
                cloud_source_region = st.text_input(
                    "üìç Region ngu·ªìn",
                    get_demo_value(demo_data, "cloud_source_region", "H·ªì Ch√≠ Minh"),
                    help="Nh·∫≠p region c·ªßa Cloud ngu·ªìn. V√≠ d·ª•: H·ªì Ch√≠ Minh.",
                    key="cloud_source_region_input"
                )

            row2_col1, row2_col2, row2_col3 = st.columns([1, 1, 1])
            with row2_col1:
                cloud_target_region = st.text_input(
                    "üìç Region ƒë√≠ch",
                    get_demo_value(demo_data, "cloud_target_region", "Asia Pacific (Singapore)"),
                    help="Nh·∫≠p region c·ªßa Cloud ƒë√≠ch. V√≠ d·ª•: Tokyo.",
                    key="cloud_target_region_input"
                )
            with row2_col2:
                replication_options = ["Full Snapshot", "CDC (Change Data Capture)"]
                replication_type = st.selectbox(
                    "üîÅ Ki·ªÉu replication",
                    replication_options,
                    index=replication_options.index(get_demo_value(demo_data, "replication_type", "Full Snapshot")) if use_demo and get_demo_value(demo_data, "replication_type", "Full Snapshot") in replication_options else 0,
                    help="Ch·ªçn ki·ªÉu replication ph√π h·ª£p. Full Snapshot ho·∫∑c CDC (Change Data Capture).",
                    key="replication_type_selectbox"
                )
            with row2_col3:
                cloud_tool_options = ["AWS DMS", "Azure Data Factory", "Google Database Migration Service", "Kh√°c"]
                cloud_tool = st.selectbox(
                    "üõ† C√¥ng c·ª• s·ª≠ d·ª•ng",
                    cloud_tool_options,
                    index=cloud_tool_options.index(get_demo_value(demo_data, "cloud_tool", "AWS DMS")) if use_demo and get_demo_value(demo_data, "cloud_tool", "AWS DMS") in cloud_tool_options else 0,
                    help="Ch·ªçn c√¥ng c·ª• migration ph√π h·ª£p v·ªõi h·ªá th·ªëng c·ªßa b·∫°n.",
                    key="cloud_tool_selectbox"
                )

            row3_col1, row3_col2, row3_col3 = st.columns([1, 1, 1])
            with row3_col1:
                live_options = ["C√≥", "Kh√¥ng"]
                is_live_system = st.selectbox(
                    "üü¢ H·ªá th·ªëng ƒëang ch·∫°y live?",
                    live_options,
                    index=0 if use_demo and get_demo_value(demo_data, "is_live_system") == "C√≥" else 1,
                    help="H·ªá th·ªëng ngu·ªìn c√≥ ƒëang ch·∫°y live kh√¥ng?",
                    key="is_live_system_selectbox"
                )
            with row3_col2:
                ha_options = ["C√≥", "Kh√¥ng"]
                ha_required = st.selectbox(
                    "üîÅ C·∫ßn High Availability?",
                    ha_options,
                    index=0 if use_demo and get_demo_value(demo_data, "ha_required") == "C√≥" else 1,
                    help="C√≥ y√™u c·∫ßu High Availability (HA) kh√¥ng?",
                    key="ha_required_selectbox"
                )
            with row3_col3:
                vpc_options = ["C√≥", "Kh√¥ng"]
                vpc_configured = st.selectbox(
                    "üåê C√≥ c·∫•u h√¨nh VPC/Subnet kh√¥ng?",
                    vpc_options,
                    index=0 if use_demo and get_demo_value(demo_data, "vpc_configured") == "C√≥" else 1,
                    help="H·ªá th·ªëng ƒë√£ c·∫•u h√¨nh VPC/Subnet ch∆∞a?",
                    key="vpc_configured_selectbox"
                )

            row4_col1 = st.columns(1)[0]
            with row4_col1:
                rollback_strategy = st.text_area(
                    "üõ°Ô∏è K·∫ø ho·∫°ch rollback",
                    get_demo_value(demo_data, "rollback_strategy", "T·∫°o snapshot tr∆∞·ªõc khi migration"),
                    help="Nh·∫≠p k·∫ø ho·∫°ch rollback n·∫øu migration th·∫•t b·∫°i. V√≠ d·ª•: T·∫°o snapshot tr∆∞·ªõc khi migration.",
                    key="rollback_strategy_textarea"
                )

            row5_col1, row5_col2, row5_col3 = st.columns([1, 1, 1])
            with row5_col1:
                strategy_options = ["Lift & Shift", "Replatform", "Refactor"]
                migration_strategy = st.selectbox(
                    "üì¶ Chi·∫øn l∆∞·ª£c chuy·ªÉn ƒë·ªïi",
                    strategy_options,
                    index=strategy_options.index(get_demo_value(demo_data, "migration_strategy", "Lift & Shift")) if use_demo and get_demo_value(demo_data, "migration_strategy", "Lift & Shift") in strategy_options else 0,
                    help="Ch·ªçn chi·∫øn l∆∞·ª£c migration: Lift & Shift (gi·ªØ nguy√™n), Replatform (thay ƒë·ªïi n·ªÅn t·∫£ng), Refactor (vi·∫øt l·∫°i).",
                    key="migration_strategy_selectbox"
                )
            with row5_col2:
                downtime_options = ["Kh√¥ng", "C√≥"]
                zero_downtime_required = st.selectbox(
                    "‚ùó C√≥ y√™u c·∫ßu Zero Downtime?",
                    downtime_options,
                    index=1 if use_demo and get_demo_value(demo_data, "zero_downtime_required") == "C√≥" else 0,
                    help="H·ªá th·ªëng c√≥ y√™u c·∫ßu ch·∫°y li√™n t·ª•c kh√¥ng downtime?",
                    key="zero_downtime_selectbox"
                )
            with row5_col3:
                testing_options = ["C√≥", "Kh√¥ng"]
                post_migration_testing = st.selectbox(
                    "üß™ C·∫ßn ki·ªÉm th·ª≠ sau migration?",
                    testing_options,
                    index=0 if use_demo and get_demo_value(demo_data, "post_migration_testing") == "C√≥" else 1,
                    help="C√≥ y√™u c·∫ßu ki·ªÉm th·ª≠ d·ªØ li·ªáu v√† h·ªá th·ªëng sau khi migration kh√¥ng?",
                    key="post_migration_testing_selectbox"
                )

            row6_col1, row6_col2, row6_col3 = st.columns([1, 1, 1])
            with row6_col1:
                dns_strategy = st.text_input(
                    "üåç Chi·∫øn l∆∞·ª£c c·∫≠p nh·∫≠t DNS / Load Balancer",
                    get_demo_value(demo_data, "dns_strategy", "S·ª≠ d·ª•ng cut-over DNS sau ki·ªÉm th·ª≠"),
                    help="Ghi r√µ c√°ch ƒë·ªãnh tuy·∫øn h·ªá th·ªëng m·ªõi sau migration. V√≠ d·ª•: chuy·ªÉn DNS sau khi ki·ªÉm th·ª≠.",
                    key="dns_strategy_input"
                )
            with row6_col2:
                env_mapping = st.text_area(
                    "üîß Bi·∫øn m√¥i tr∆∞·ªùng c·∫ßn chuy·ªÉn ƒë·ªïi",
                    get_demo_value(demo_data, "env_mapping", "DB_HOST, API_ENDPOINT, ..."),
                    help="Li·ªát k√™ ho·∫∑c m√¥ t·∫£ bi·∫øn m√¥i tr∆∞·ªùng c·∫ßn mapping khi chuy·ªÉn h·ªá th·ªëng.",
                    key="env_mapping_input"
                )
            with row6_col3:
                monitoring_options = ["C√≥", "Kh√¥ng"]
                monitoring_required = st.selectbox(
                    "üìà C·∫ßn gi√°m s√°t sau khi chuy·ªÉn ƒë·ªïi?",
                    monitoring_options,
                    index=0 if use_demo and get_demo_value(demo_data, "monitoring_required") == "C√≥" else 1,
                    help="C√≥ tri·ªÉn khai c√¥ng c·ª• gi√°m s√°t sau khi migration kh√¥ng?",
                    key="monitoring_required_selectbox"
                )

            # Th√™m th√¥ng tin chi ti·∫øt cho Cloud-to-Cloud migration
            st.markdown("### üìä Th√¥ng tin chi ti·∫øt d·ªØ li·ªáu")
            
            row7_col1, row7_col2, row7_col3 = st.columns([1, 1, 1])
            with row7_col1:
                data_size_gb = st.number_input(
                    "üíæ Dung l∆∞·ª£ng d·ªØ li·ªáu (GB)",
                    min_value=1,
                    value=get_demo_value(demo_data, "data_size_gb", 100) if use_demo else 100,
                    help="T·ªïng dung l∆∞·ª£ng d·ªØ li·ªáu c·∫ßn migration (GB)",
                    key="data_size_gb_input"
                )
            with row7_col2:
                data_type_options = ["Transactional", "Static Files", "Transactional + Static", "Real-time", "Batch"]
                data_type = st.selectbox(
                    "üìã Lo·∫°i d·ªØ li·ªáu",
                    data_type_options,
                    index=data_type_options.index(get_demo_value(demo_data, "data_type", "Transactional")) if use_demo and get_demo_value(demo_data, "data_type", "Transactional") in data_type_options else 0,
                    help="Ch·ªçn lo·∫°i d·ªØ li·ªáu ch√≠nh trong h·ªá th·ªëng",
                    key="data_type_selectbox"
                )
            with row7_col3:
                change_rate_options = ["Th·∫•p", "Trung b√¨nh", "Cao", "R·∫•t cao"]
                change_rate = st.selectbox(
                    "üîÑ T·ªëc ƒë·ªô thay ƒë·ªïi d·ªØ li·ªáu",
                    change_rate_options,
                    index=change_rate_options.index(get_demo_value(demo_data, "change_rate", "Trung b√¨nh")) if use_demo and get_demo_value(demo_data, "change_rate", "Trung b√¨nh") in change_rate_options else 1,
                    help="T·ªëc ƒë·ªô c·∫≠p nh·∫≠t/th√™m/x√≥a d·ªØ li·ªáu hi·ªán t·∫°i",
                    key="change_rate_selectbox"
                )

            row8_col1, row8_col2, row8_col3 = st.columns([1, 1, 1])
            with row8_col1:
                current_service = st.text_input(
                    "üè¢ D·ªãch v·ª• hi·ªán t·∫°i",
                    get_demo_value(demo_data, "current_service", "AWS RDS PostgreSQL"),
                    help="D·ªãch v·ª• cloud hi·ªán t·∫°i (v√≠ d·ª•: AWS RDS, Azure SQL, GCP Cloud SQL)",
                    key="current_service_input"
                )
            with row8_col2:
                target_service = st.text_input(
                    "üéØ D·ªãch v·ª• ƒë√≠ch mong mu·ªën",
                    get_demo_value(demo_data, "target_service", "Azure SQL Database"),
                    help="D·ªãch v·ª• cloud ƒë√≠ch mong mu·ªën",
                    key="target_service_input"
                )
            with row8_col3:
                network_options = ["Public Internet", "VPN", "Dedicated Interconnect", "Direct Connect/ExpressRoute"]
                network_connection = st.selectbox(
                    "üåê C√°ch k·∫øt n·ªëi hi·ªán t·∫°i",
                    network_options,
                    index=network_options.index(get_demo_value(demo_data, "network_connection", "VPN")) if use_demo and get_demo_value(demo_data, "network_connection", "VPN") in network_options else 1,
                    help="Ph∆∞∆°ng th·ª©c k·∫øt n·ªëi gi·ªØa c√°c cloud",
                    key="network_connection_selectbox"
                )

            row9_col1, row9_col2, row9_col3 = st.columns([1, 1, 1])
            with row9_col1:
                data_structure = st.text_area(
                    "üèóÔ∏è C·∫•u tr√∫c d·ªØ li·ªáu",
                    get_demo_value(demo_data, "data_structure", "Schema, quan h·ªá, index, trigger, view, stored procedure..."),
                    help="M√¥ t·∫£ c·∫•u tr√∫c d·ªØ li·ªáu hi·ªán t·∫°i",
                    key="data_structure_textarea"
                )
            with row9_col2:
                partitioning_options = ["Kh√¥ng c√≥", "C√≥ ph√¢n v√πng", "C√≥ sharding", "Ph√¢n m·∫£nh cao"]
                data_partitioning = st.selectbox(
                    "üì¶ Ph√¢n v√πng d·ªØ li·ªáu",
                    partitioning_options,
                    index=partitioning_options.index(get_demo_value(demo_data, "data_partitioning", "Kh√¥ng c√≥")) if use_demo and get_demo_value(demo_data, "data_partitioning", "Kh√¥ng c√≥") in partitioning_options else 0,
                    help="T√¨nh tr·∫°ng ph√¢n v√πng/sharding d·ªØ li·ªáu",
                    key="data_partitioning_selectbox"
                )
            with row9_col3:
                downtime_tolerance = st.text_input(
                    "‚è±Ô∏è Ch·∫•p nh·∫≠n downtime",
                    get_demo_value(demo_data, "downtime_tolerance", "30 ph√∫t"),
                    help="Th·ªùi gian downtime t·ªëi ƒëa c√≥ th·ªÉ ch·∫•p nh·∫≠n",
                    key="downtime_tolerance_input"
                )

            row10_col1, row10_col2 = st.columns([1, 1])
            with row10_col1:
                security_requirements = st.text_area(
                    "üîê Y√™u c·∫ßu b·∫£o m·∫≠t",
                    get_demo_value(demo_data, "security_requirements", "M√£ h√≥a d·ªØ li·ªáu khi chuy·ªÉn, IAM/ACLs, compliance..."),
                    help="C√°c y√™u c·∫ßu b·∫£o m·∫≠t c·∫ßn thi·∫øt",
                    key="security_requirements_textarea"
                )
            with row10_col2:
                compatibility_options = ["Kh√¥ng c·∫ßn thay ƒë·ªïi", "C·∫ßn ch·ªânh s·ª≠a nh·ªè", "C·∫ßn refactor l·ªõn", "C·∫ßn vi·∫øt l·∫°i"]
                app_compatibility = st.selectbox(
                    "üîß ƒê·ªô t∆∞∆°ng th√≠ch ·ª©ng d·ª•ng",
                    compatibility_options,
                    index=compatibility_options.index(get_demo_value(demo_data, "app_compatibility", "Kh√¥ng c·∫ßn thay ƒë·ªïi")) if use_demo and get_demo_value(demo_data, "app_compatibility", "Kh√¥ng c·∫ßn thay ƒë·ªïi") in compatibility_options else 0,
                    help="M·ª©c ƒë·ªô c·∫ßn ch·ªânh s·ª≠a ·ª©ng d·ª•ng",
                    key="app_compatibility_selectbox"
                )

            row11_col1 = st.columns(1)[0]
            with row11_col1:
                external_dependencies = st.text_area(
                    "üîó D·ªãch v·ª• t√≠ch h·ª£p b√™n ngo√†i",
                    get_demo_value(demo_data, "external_dependencies", "Salesforce API, RabbitMQ, Redis, Elasticsearch..."),
                    help="C√°c d·ªãch v·ª• b√™n ngo√†i h·ªá th·ªëng c·∫ßn chuy·ªÉn c·∫•u h√¨nh",
                    key="external_dependencies_textarea"
                )
            version = None
            data_size = None
            bandwidth = None
            downtime = None
            security_level = None
            system_scale = None

        submit = st.form_submit_button("üöÄ T·∫°o k·∫ø ho·∫°ch Migration")

    # Ph·∫£n h·ªìi sau khi submit
    if 'submit' in locals() and submit:
        st.success("‚úÖ ƒê√£ nh·∫≠n th√¥ng tin. ƒêang x·ª≠ l√Ω k·∫ø ho·∫°ch migration...")

    result = {
        "submit": submit,
        "migration_type": migration_type,
        "db_type": db_type,
        "version": version,
        "data_size": data_size,
        "bandwidth": bandwidth,
        "downtime": downtime,
        "cloud_target": cloud_target,
        "cloud_source": cloud_source if migration_type == "Cloud ‚ûú Cloud" else "On-Premise",
        "security_level": security_level,
        "system_scale": system_scale,
    }
    # Add extra fields for Cloud ‚ûú Cloud
    if migration_type == "Cloud ‚ûú Cloud":
        result.update({
            "replication_type": replication_type,
            "cloud_tool": cloud_tool,
            "cloud_source_region": cloud_source_region,
            "cloud_target_region": cloud_target_region,
            "is_live_system": is_live_system,
            "ha_required": ha_required,
            "vpc_configured": vpc_configured,
            "rollback_strategy": rollback_strategy,
            "migration_strategy": migration_strategy,
            "zero_downtime_required": zero_downtime_required,
            "post_migration_testing": post_migration_testing,
            "dns_strategy": dns_strategy,
            "env_mapping": env_mapping,
            "monitoring_required": monitoring_required,
            # Th√¥ng tin chi ti·∫øt d·ªØ li·ªáu
            "data_size_gb": data_size_gb,
            "data_type": data_type,
            "change_rate": change_rate,
            "current_service": current_service,
            "target_service": target_service,
            "network_connection": network_connection,
            "data_structure": data_structure,
            "data_partitioning": data_partitioning,
            "downtime_tolerance": downtime_tolerance,
            "security_requirements": security_requirements,
            "app_compatibility": app_compatibility,
            "external_dependencies": external_dependencies,
        })
    return result

def build_system_info(user_input):
    system_info = f"""
- Ki·ªÉu Migration: {user_input['migration_type']}
- Cloud ngu·ªìn: {user_input['cloud_source']}
- Cloud ƒë√≠ch: {user_input['cloud_target']}
- Database: {user_input['db_type']}, phi√™n b·∫£n {user_input['version']}
- Dung l∆∞·ª£ng d·ªØ li·ªáu: {user_input['data_size']}
- BƒÉng th√¥ng m·∫°ng: {user_input['bandwidth']}
- Downtime t·ªëi ƒëa: {user_input['downtime']}
- M·ª©c ƒë·ªô b·∫£o m·∫≠t: {user_input['security_level']}
- Quy m√¥ h·ªá th·ªëng: {user_input['system_scale']}
"""
    if user_input.get("migration_type") == "Cloud ‚ûú Cloud":
        system_info += f"""
- C√¥ng c·ª•: {user_input.get('cloud_tool','')}
- Ki·ªÉu replication: {user_input.get('replication_type','')}
- Cloud source region: {user_input.get('cloud_source_region','')}
- Cloud target region: {user_input.get('cloud_target_region','')}
- Live system: {user_input.get('is_live_system','')}
- HA Required: {user_input.get('ha_required','')}
- VPC/Subnet Configured: {user_input.get('vpc_configured','')}
- Rollback Strategy: {user_input.get('rollback_strategy','')}
- Chi·∫øn l∆∞·ª£c migration: {user_input.get('migration_strategy','')}
- Zero Downtime y√™u c·∫ßu: {user_input.get('zero_downtime_required','')}
- Ki·ªÉm th·ª≠ sau migration: {user_input.get('post_migration_testing','')}
- DNS / Load Balancer Strategy: {user_input.get('dns_strategy','')}
- Bi·∫øn m√¥i tr∆∞·ªùng c·∫ßn mapping: {user_input.get('env_mapping','')}
- Gi√°m s√°t sau migration: {user_input.get('monitoring_required','')}

üìä TH√îNG TIN CHI TI·∫æT D·ªÆ LI·ªÜU:
- Dung l∆∞·ª£ng d·ªØ li·ªáu: {user_input.get('data_size_gb','')} GB
- Lo·∫°i d·ªØ li·ªáu: {user_input.get('data_type','')}
- T·ªëc ƒë·ªô thay ƒë·ªïi: {user_input.get('change_rate','')}
- D·ªãch v·ª• hi·ªán t·∫°i: {user_input.get('current_service','')}
- D·ªãch v·ª• ƒë√≠ch: {user_input.get('target_service','')}
- K·∫øt n·ªëi m·∫°ng: {user_input.get('network_connection','')}
- C·∫•u tr√∫c d·ªØ li·ªáu: {user_input.get('data_structure','')}
- Ph√¢n v√πng d·ªØ li·ªáu: {user_input.get('data_partitioning','')}
- Ch·∫•p nh·∫≠n downtime: {user_input.get('downtime_tolerance','')}
- Y√™u c·∫ßu b·∫£o m·∫≠t: {user_input.get('security_requirements','')}
- T∆∞∆°ng th√≠ch ·ª©ng d·ª•ng: {user_input.get('app_compatibility','')}
- D·ªãch v·ª• t√≠ch h·ª£p: {user_input.get('external_dependencies','')}
"""
    return system_info

def build_json_for_ai(user_input):
    """
    T·∫°o ƒë·ªãnh d·∫°ng JSON chu·∫©n h√≥a cho AI x·ª≠ l√Ω migration
    """
    import json
    
    # X·ª≠ l√Ω downtime tolerance t·ª´ text sang minutes
    downtime_text = user_input.get('downtime_tolerance', '30 ph√∫t')
    downtime_minutes = 30  # default
    if 'ph√∫t' in downtime_text or 'minute' in downtime_text:
        try:
            downtime_minutes = int(''.join(filter(str.isdigit, downtime_text)))
        except:
            downtime_minutes = 30
    
    # X·ª≠ l√Ω data partitioning t·ª´ text sang boolean
    partitioning_text = user_input.get('data_partitioning', 'Kh√¥ng c√≥')
    data_partitioning = partitioning_text not in ['Kh√¥ng c√≥', 'None']
    
    # X·ª≠ l√Ω change rate mapping
    change_rate_mapping = {
        'Th·∫•p': 'Low',
        'Trung b√¨nh': 'Medium', 
        'Cao': 'High',
        'R·∫•t cao': 'Very High'
    }
    data_change_rate = change_rate_mapping.get(user_input.get('change_rate', 'Trung b√¨nh'), 'Medium')
    
    # X·ª≠ l√Ω network type mapping
    network_mapping = {
        'Public Internet': 'Public',
        'VPN': 'VPN',
        'Dedicated Interconnect': 'Dedicated',
        'Direct Connect/ExpressRoute': 'DirectConnect'
    }
    network_type = network_mapping.get(user_input.get('network_connection', 'VPN'), 'VPN')
    
    # X·ª≠ l√Ω external dependencies t·ª´ text sang list
    external_deps_text = user_input.get('external_dependencies', '')
    external_integrations = []
    if external_deps_text:
        # T√°ch c√°c d·ªãch v·ª• b·∫±ng d·∫•u ph·∫©y ho·∫∑c xu·ªëng d√≤ng
        deps = external_deps_text.replace('\n', ',').split(',')
        external_integrations = [dep.strip() for dep in deps if dep.strip()]
    
    # X·ª≠ l√Ω security requirements
    security_text = user_input.get('security_requirements', '')
    security_policies = []
    if 'm√£ h√≥a' in security_text.lower() or 'encryption' in security_text.lower():
        security_policies.append('AES256 encryption')
    if 'iam' in security_text.lower():
        security_policies.append('Preserve IAM')
    if 'compliance' in security_text.lower():
        security_policies.append('Compliance requirements')
    if not security_policies:
        security_policies = ['Standard encryption']
    
    # X√°c ƒë·ªãnh critical level d·ª±a tr√™n c√°c y·∫øu t·ªë
    critical_level = 'Medium'
    if (user_input.get('zero_downtime_required') == 'C√≥' or 
        user_input.get('ha_required') == 'C√≥' or
        user_input.get('data_size_gb', 0) > 500):
        critical_level = 'High'
    elif user_input.get('data_size_gb', 0) < 50:
        critical_level = 'Low'
    
    # T·∫°o JSON structure
    migration_json = {
        "current_cloud_provider": user_input.get('cloud_source', 'Unknown'),
        "target_cloud_provider": user_input.get('cloud_target', 'Unknown'),
        "data_type": user_input.get('data_type', 'Transactional'),
        "data_size_gb": user_input.get('data_size_gb', 100),
        "data_change_rate": data_change_rate,
        "downtime_window_minutes": downtime_minutes,
        "network_type": network_type,
        "data_partitioning": data_partitioning,
        "source_services": [user_input.get('current_service', 'Unknown')],
        "target_services": [user_input.get('target_service', 'Unknown')],
        "security_policies": security_policies,
        "external_integrations": external_integrations,
        "app_dependency_notes": user_input.get('app_compatibility', 'No changes required'),
        "schema_notes": user_input.get('data_structure', 'Standard schema'),
        "critical_level": critical_level,
        # Th√™m c√°c tr∆∞·ªùng b·ªï sung
        "migration_strategy": user_input.get('migration_strategy', 'Lift & Shift'),
        "zero_downtime_required": user_input.get('zero_downtime_required') == 'C√≥',
        "post_migration_testing": user_input.get('post_migration_testing') == 'C√≥',
        "monitoring_required": user_input.get('monitoring_required') == 'C√≥',
        "replication_type": user_input.get('replication_type', 'Full Snapshot'),
        "cloud_tool": user_input.get('cloud_tool', 'AWS DMS'),
        "source_region": user_input.get('cloud_source_region', 'Unknown'),
        "target_region": user_input.get('cloud_target_region', 'Unknown'),
        "is_live_system": user_input.get('is_live_system') == 'C√≥',
        "ha_required": user_input.get('ha_required') == 'C√≥',
        "vpc_configured": user_input.get('vpc_configured') == 'C√≥',
        "rollback_strategy": user_input.get('rollback_strategy', 'Create snapshot before migration'),
        "dns_strategy": user_input.get('dns_strategy', 'Cut-over DNS after testing'),
        "env_mapping": user_input.get('env_mapping', 'DB_HOST, API_ENDPOINT'),
        "migration_type": user_input.get('migration_type', 'Cloud ‚ûú Cloud')
    }
    
    return json.dumps(migration_json, indent=2, ensure_ascii=False)

def get_demo_value(demo_data, key, default=""):
    """
    L·∫•y gi√° tr·ªã demo cho input field
    """
    if demo_data and key in demo_data:
        return demo_data[key]
    return default

def create_demo_data():
    """
    T·∫°o d·ªØ li·ªáu demo cho Cloud-to-Cloud migration
    """
    demo_data = {
        "migration_type": "Cloud ‚ûú Cloud",
        "cloud_source": "AWS",
        "cloud_target": "Azure",
        "db_type": "PostgreSQL",
        "version": "14",
        "data_size": "850 GB",
        "bandwidth": "1 Gbps",
        "downtime": "30 ph√∫t",
        "cloud_target": "Azure",
        "cloud_source": "AWS",
        "security_level": "Tu√¢n th·ªß PCI DSS",
        "system_scale": "T·∫≠p ƒëo√†n l·ªõn",
        "replication_type": "CDC (Change Data Capture)",
        "cloud_tool": "AWS DMS",
        "cloud_source_region": "US East (N. Virginia)",
        "cloud_target_region": "East US",
        "is_live_system": "C√≥",
        "ha_required": "C√≥",
        "vpc_configured": "C√≥",
        "rollback_strategy": "T·∫°o snapshot tr∆∞·ªõc khi migration, backup real-time",
        "migration_strategy": "Replatform",
        "zero_downtime_required": "C√≥",
        "post_migration_testing": "C√≥",
        "dns_strategy": "Blue-green deployment v·ªõi cut-over DNS",
        "env_mapping": "DB_HOST, API_ENDPOINT, S3_BUCKET, LAMBDA_FUNCTIONS",
        "monitoring_required": "C√≥",
        # Th√¥ng tin chi ti·∫øt d·ªØ li·ªáu
        "data_size_gb": 850,
        "data_type": "Transactional + Static",
        "change_rate": "Trung b√¨nh",
        "current_service": "AWS S3, RDS PostgreSQL, Lambda",
        "target_service": "Azure Blob Storage, Azure Database for PostgreSQL, Azure Functions",
        "network_connection": "VPN",
        "data_structure": "Schema ph·ª©c t·∫°p v·ªõi stored procedures, triggers, views. Ph√¢n v√πng theo khu v·ª±c v√† kh√°ch h√†ng. Index t·ªëi ∆∞u cho queries th∆∞·ªùng xuy√™n.",
        "data_partitioning": "C√≥ ph√¢n v√πng",
        "downtime_tolerance": "30 ph√∫t",
        "security_requirements": "M√£ h√≥a AES256 khi chuy·ªÉn d·ªØ li·ªáu, gi·ªØ nguy√™n ph√¢n quy·ªÅn IAM, tu√¢n th·ªß PCI DSS, audit trail ƒë·∫ßy ƒë·ªß",
        "app_compatibility": "C·∫ßn ch·ªânh s·ª≠a nh·ªè",
        "external_dependencies": "Salesforce API, RabbitMQ, Redis Cache, Elasticsearch, Payment Gateway"
    }
    return demo_data

def display_migration_json(user_input):
    """
    Hi·ªÉn th·ªã JSON format cho AI trong Streamlit
    """
    import streamlit as st
    
    json_data = build_json_for_ai(user_input)
    
    st.markdown("### ü§ñ D·ªØ li·ªáu JSON cho AI x·ª≠ l√Ω")
    st.code(json_data, language="json")
    
    # Th√™m n√∫t copy
    st.markdown("**üìã Click ƒë·ªÉ copy JSON data:**")
    st.text_area("JSON Data", json_data, height=300, key="json_display")
    
    return json_data

def build_ai_prompt_with_json(user_input):
    """
    T·∫°o prompt cho AI v·ªõi JSON format
    """
    json_data = build_json_for_ai(user_input)
    
    prompt = f"""
B·∫°n l√† chuy√™n gia Cloud Migration v·ªõi 15+ nƒÉm kinh nghi·ªám. 
D∆∞·ªõi ƒë√¢y l√† th√¥ng tin chi ti·∫øt v·ªÅ d·ª± √°n migration:

```json
{json_data}
```

D·ª±a tr√™n th√¥ng tin n√†y, h√£y t·∫°o m·ªôt k·∫ø ho·∫°ch migration chi ti·∫øt bao g·ªìm:

1. **Ph√¢n t√≠ch r·ªßi ro v√† th√°ch th·ª©c**
2. **Chi·∫øn l∆∞·ª£c migration ph√π h·ª£p** (d·ª±a tr√™n data_change_rate, downtime_window_minutes)
3. **Timeline chi ti·∫øt** (d·ª±a tr√™n data_size_gb, network_type)
4. **C√¥ng c·ª• v√† script c·∫ßn thi·∫øt**
5. **K·∫ø ho·∫°ch rollback**
6. **Checklist validation**
7. **∆Ø·ªõc t√≠nh chi ph√≠** (n·∫øu c√≥ th·ªÉ)

H√£y ƒë∆∞a ra c√°c khuy·∫øn ngh·ªã c·ª• th·ªÉ d·ª±a tr√™n:
- Critical level: {user_input.get('critical_level', 'Medium')}
- Network type: {user_input.get('network_connection', 'VPN')}
- Data partitioning: {user_input.get('data_partitioning', 'Kh√¥ng c√≥')}
- External integrations: {user_input.get('external_dependencies', 'None')}
"""
    
    return prompt

def show_demo_migration():
    """
    Hi·ªÉn th·ªã demo migration v·ªõi d·ªØ li·ªáu m·∫´u
    """
    import streamlit as st
    
    demo_data = create_demo_data()
    
    st.markdown("## üöÄ Demo: Cloud-to-Cloud Migration")
    st.markdown("### üìä Th√¥ng tin n·ªÅn t·∫£ng & d·ªãch v·ª•")
    
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**N·ªÅn t·∫£ng hi·ªán t·∫°i:** AWS")
        st.markdown("**N·ªÅn t·∫£ng ƒë√≠ch:** Azure")
        st.markdown("**Lo·∫°i d·ªØ li·ªáu:** Transactional + Static")
        st.markdown("**Dung l∆∞·ª£ng d·ªØ li·ªáu:** ~850 GB")
        st.markdown("**T·ªëc ƒë·ªô thay ƒë·ªïi d·ªØ li·ªáu:** Trung b√¨nh (1‚Äì5% m·ªói gi·ªù)")
        st.markdown("**C·ª≠a s·ªï downtime cho ph√©p:** 30 ph√∫t")
        st.markdown("**M·∫°ng truy·ªÅn d·ªØ li·ªáu:** VPN ri√™ng")
    
    with col2:
        st.markdown("**Ph√¢n v√πng d·ªØ li·ªáu:** C√≥ (theo khu v·ª±c, kh√°ch h√†ng)")
        st.markdown("**D·ªãch v·ª• ngu·ªìn:** S3, RDS (PostgreSQL), Lambda")
        st.markdown("**D·ªãch v·ª• ƒë√≠ch t∆∞∆°ng ·ª©ng:** Blob Storage, Azure Database, Azure Functions")
        st.markdown("**Ch√≠nh s√°ch b·∫£o m·∫≠t:** M√£ h√≥a AES256, gi·ªØ nguy√™n ph√¢n quy·ªÅn IAM")
        st.markdown("**T√≠ch h·ª£p h·ªá th·ªëng ngo√†i:** Salesforce API, RabbitMQ")
        st.markdown("**Ph·ª• thu·ªôc ·ª©ng d·ª•ng:** C·∫ßn c·∫≠p nh·∫≠t connection string sau migration")
        st.markdown("**M·ª©c ƒë·ªô quan tr·ªçng:** Cao (·∫£nh h∆∞·ªüng tr·ª±c ti·∫øp ƒë·∫øn kinh doanh)")
    
    st.markdown("### ü§ñ JSON Output cho AI x·ª≠ l√Ω")
    
    # T·∫°o JSON t·ª´ demo data
    json_output = build_json_for_ai(demo_data)
    
    st.code(json_output, language="json")
    
    st.markdown("### üìã Th√¥ng tin chi ti·∫øt ƒë∆∞·ª£c x·ª≠ l√Ω:")
    
    # Hi·ªÉn th·ªã system info
    system_info = build_system_info(demo_data)
    st.text(system_info)
    
    return demo_data, json_output

def build_prompts(system_info, migration_type=None):
    # N·∫øu migration_type ch∆∞a truy·ªÅn v√†o, l·∫•y t·ª´ system_info n·∫øu c√≥
    if migration_type is None and isinstance(system_info, dict):
        migration_type = system_info.get('migration_type', None)
    elif migration_type is None and isinstance(system_info, str):
        migration_type = None

    # Prompt cho Cloud ‚ûú Cloud s·∫Ω nh·∫•n m·∫°nh ph√¢n t√≠ch s·ª± kh√°c bi·ªát gi·ªØa c√°c cloud
    overview_prompt = f"""
B·∫°n l√† chuy√™n gia v·ªÅ migration c∆° s·ªü d·ªØ li·ªáu v·ªõi 20 nƒÉm kinh nghi·ªám. V·ªõi th√¥ng tin sau:
{system_info}

üëâ H√£y ph√¢n t√≠ch t·ªïng quan h·ªá th·ªëng v√† gi·∫£i th√≠ch v√¨ sao n√™n ch·ªçn chi·∫øn l∆∞·ª£c ph√π h·ª£p (Logical Replication vs Snapshot vs Dump & Restore).
"""
    if migration_type == "Cloud ‚ûú Cloud":
        overview_prompt += "\nN·∫øu migration l√† t·ª´ Cloud ‚ûú Cloud, h√£y ph√¢n t√≠ch th√™m s·ª± kh√°c bi·ªát gi·ªØa c√°c n·ªÅn t·∫£ng cloud, t∆∞∆°ng th√≠ch c√¥ng c·ª• v√† chi ph√≠."

    return {
        "overview": overview_prompt,
        "steps": f"""
B·∫°n l√† chuy√™n gia tri·ªÉn khai migration h·ªá th·ªëng ph·ª©c t·∫°p. V·ªõi th√¥ng tin:
{system_info}

üëâ H√£y m√¥ t·∫£ chi ti·∫øt c√°c b∆∞·ªõc migration theo 3 giai ƒëo·∫°n: Before, During, After. Bao g·ªìm:
- Checklist k·ªπ thu·∫≠t
- Chi·∫øn l∆∞·ª£c rollback n·∫øu l·ªói
- G·ª£i √Ω c√¥ng c·ª• (pg_dump, Bucardo, DMS, v.v.)
- Ghi ch√∫ ƒë∆°n gi·∫£n cho ng∆∞·ªùi m·ªõi
""",
        "time_estimation": f"""
B·∫°n l√† k·ªπ s∆∞ m·∫°ng. V·ªõi d·ªØ li·ªáu dung l∆∞·ª£ng {system_info}, h√£y t√≠nh to√°n th·ªùi gian truy·ªÅn t·∫£i chi ti·∫øt (ƒë·ªïi ƒë∆°n v·ªã n·∫øu c·∫ßn), bao g·ªìm margin th·ªùi gian cho downtime, ki·ªÉm th·ª≠ v√† x·ª≠ l√Ω b·∫•t ng·ªù.
""",
        "security": f"""
B·∫°n l√† chuy√™n gia b·∫£o m·∫≠t. V·ªõi y√™u c·∫ßu h·ªá th·ªëng:
{system_info}

üëâ H√£y ƒë·ªÅ xu·∫•t chi·∫øn l∆∞·ª£c b·∫£o m·∫≠t to√†n di·ªán cho migration, bao g·ªìm:
- IAM, m√£ h√≥a d·ªØ li·ªáu
- Logging & Audit trail
- C√¥ng c·ª• cloud-native khuy·∫øn ngh·ªã
""",
        "validation": f"""
Sau migration, l√†m sao ƒë·ªÉ ƒë·∫£m b·∫£o d·ªØ li·ªáu ƒë√∫ng v√† h·ªá th·ªëng ho·∫°t ƒë·ªông chu·∫©n?
üëâ Vi·∫øt checklist x√°c minh d·ªØ li·ªáu: checksum, query test, hi·ªáu nƒÉng, so s√°nh k·∫øt qu·∫£.
""",
        "improvement": f"""
Sau migration, h·ªá th·ªëng c√≥ th·ªÉ c·∫£i ti·∫øn ra sao?
üëâ ƒê·ªÅ xu·∫•t: High Availability, Hybrid Cloud, t·ª± ƒë·ªông h√≥a DevOps...
""",
        "cloud_architect_plan": f"""
B·∫°n h√£y ƒë√≥ng vai tr√≤ l√† m·ªôt chuy√™n gia Cloud Architect.
T√¥i mu·ªën b·∫°n gi√∫p thi·∫øt k·∫ø m·ªôt k·∫ø ho·∫°ch migration h·ªá th·ªëng t·ª´ [ngu·ªìn] sang [ƒë√≠ch].
V·ªõi th√¥ng tin sau:
{system_info}

H√£y tr√¨nh b√†y k·∫ø ho·∫°ch theo c·∫•u tr√∫c d·ªÖ hi·ªÉu g·ªìm c√°c ph·∫ßn sau:
1. T·ªïng quan ng·∫Øn g·ªçn v·ªÅ m·ª•c ti√™u migration
2. C√°c b∆∞·ªõc chi ti·∫øt, ƒë√°nh s·ªë r√µ r√†ng (1, 2, 3...)
3. Th·ªùi gian d·ª± ki·∫øn cho t·ª´ng b∆∞·ªõc
4. BƒÉng th√¥ng c·∫ßn thi·∫øt v√† dung l∆∞·ª£ng truy·ªÅn t·∫£i (∆∞·ªõc l∆∞·ª£ng theo GB v√† Mbps n·∫øu c√≥ th·ªÉ)
5. S∆° ƒë·ªì ki·∫øn tr√∫c tr∆∞·ªõc v√† sau khi migration (c√≥ th·ªÉ m√¥ t·∫£ b·∫±ng s∆° ƒë·ªì text ho·∫∑c bi·ªÉu ƒë·ªì block ƒë∆°n gi·∫£n)
6. C√°c r·ªßi ro v√† c√°ch gi·∫£m thi·ªÉu
7. G·ª£i √Ω c√¥ng c·ª• ho·∫∑c script h·ªó tr·ª£ (n·∫øu c√≥)
""",
        "ai_json_analysis": build_ai_prompt_with_json(system_info) if isinstance(system_info, dict) else f"""
B·∫°n l√† chuy√™n gia Cloud Migration v·ªõi 15+ nƒÉm kinh nghi·ªám. 
V·ªõi th√¥ng tin sau:
{system_info}

H√£y t·∫°o m·ªôt k·∫ø ho·∫°ch migration chi ti·∫øt bao g·ªìm:
1. **Ph√¢n t√≠ch r·ªßi ro v√† th√°ch th·ª©c**
2. **Chi·∫øn l∆∞·ª£c migration ph√π h·ª£p**
3. **Timeline chi ti·∫øt**
4. **C√¥ng c·ª• v√† script c·∫ßn thi·∫øt**
5. **K·∫ø ho·∫°ch rollback**
6. **Checklist validation**
7. **∆Ø·ªõc t√≠nh chi ph√≠** (n·∫øu c√≥ th·ªÉ)
"""
    } 